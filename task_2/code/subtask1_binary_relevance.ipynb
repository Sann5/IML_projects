{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2, Subtask 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We read the already normalized and imputed data\n",
    "test_feat_path = \"../data/test_features_imp.csv\" \n",
    "train_feat_path = \"../data/train_features_imp.csv\" \n",
    "train_lab_path = \"../data/train_labels.csv\"\n",
    "\n",
    "test_feat = pd.read_csv(test_feat_path)\n",
    "train_feat = pd.read_csv(train_feat_path)\n",
    "train_lab = pd.read_csv(train_lab_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Order data to make sure that rows in X and Y match\n",
    "test_feat.sort_values(by=['pid'], inplace = True, ignore_index = True)\n",
    "train_feat.sort_values(by=['pid'], inplace = True, ignore_index = True)\n",
    "train_lab.sort_values(by=['pid'], inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select relevant label columns and exclude the pid column\n",
    "X_test = train_feat.iloc[:, 1:170].values\n",
    "X_train = train_feat.iloc[:, 1:170].values\n",
    "train_lab = train_lab[[\"LABEL_BaseExcess\", \"LABEL_Fibrinogen\",\n",
    "                   \"LABEL_AST\", \"LABEL_Alkalinephos\",\n",
    "                   \"LABEL_Bilirubin_total\", \"LABEL_Lactate\",\n",
    "                   \"LABEL_TroponinI\", \"LABEL_SaO2\",\n",
    "                   \"LABEL_Bilirubin_direct\", \"LABEL_EtCO2\"]]\n",
    "Y_train = train_lab.iloc[:,:].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make C-Contiguos so the data doesnt have to be copied\n",
    "X_test = np.ascontiguousarray(X_test, dtype=np.double)\n",
    "X_train = np.ascontiguousarray(X_train, dtype=np.double)\n",
    "Y_train = np.ascontiguousarray(Y_train, dtype=np.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train binary relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Binary Relevance multi-label classifier\n",
    "# with an SVM classifier\n",
    "\n",
    "classifier = BinaryRelevance(\n",
    "    # Specifying SVM parameters\n",
    "    classifier = SVC(C = 1,                     # Regularization term, by default 1\n",
    "                     kernel = 'rbf',            # Kernell to be used, by default rbf\n",
    "                     gamma = 'scale',           # Gamma parameter in 'rbf' kernell, by default 'scale' = 1 / (n_features * X.var()) \n",
    "                     probability = True,        # Probability estimates for the label predictions p(y_i = 1 | y^_i)\n",
    "                     class_weight = 'balanced', # Weights to be used to balance data set. 'balanced' = n_samples / (n_classes * np.bincount(y))\n",
    "                     random_state = 123,        # Controls the pseudo random number generation for shuffling the data for probability estimates.\n",
    "                     cache_size = 1000),        # Specify the size of the kernel cache (in MB). By default 200, increased to 1000 to improve runtime.\n",
    "    require_dense = [False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=SVC(C=1, cache_size=1000, class_weight='balanced',\n",
       "                               probability=True, random_state=123),\n",
       "                require_dense=[False, True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perfomrance of the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6282168702674115"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Y_train, Y_pred, average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write probabilities to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = pd.DataFrame(probabilities.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities.to_csv('../output/subtask_1_output', index = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 6159.6947519779205 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102.66157919963202"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6159.6947519779205 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   | C | kernel | gamma | weight | features | n_features | F1 score | runtime (min) |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| run_1 |  1 |  rbf | scale  |  balanced |  median for NA's and mean  | 35 | 0.598165656150447 | 33 |\n",
    "| run_2 |  1 |  rbf | scale  |  balanced |  median for NA's and mean, max, min, median, sd  | 170 | 0.6282168702674115 | 102 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
