{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2, Subtask 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We read the already normalized and imputed data. For specifics about the imputation and normalization \n",
    "## see imputate.R file. \n",
    "test_feat_path = \"../data/test_features_imp.csv\" \n",
    "train_feat_path = \"../data/train_features_imp.csv\" \n",
    "train_lab_path = \"../data/train_labels.csv\"\n",
    "test_feat = pd.read_csv(test_feat_path)\n",
    "train_feat = pd.read_csv(train_feat_path)\n",
    "train_lab = pd.read_csv(train_lab_path)\n",
    "\n",
    "## Order data to make sure that rows in X and Y match\n",
    "test_feat.sort_values(by=['pid'], inplace = True, ignore_index = True)\n",
    "train_feat.sort_values(by=['pid'], inplace = True,ignore_index = True)\n",
    "train_lab.sort_values(by=['pid'], inplace = True, ignore_index = True)\n",
    "\n",
    "## Select exclude the pid column and make into array\n",
    "X_test = test_feat.iloc[:, 1:272].values\n",
    "X_train = train_feat.iloc[:, 1:272].values\n",
    "Y_train = train_lab\n",
    "\n",
    "# Create output file with the pid\n",
    "output = pd.DataFrame({'pid': test_feat.iloc[:, 0].values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05739944, -0.06778105,  0.27955497, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.77044298,  0.46745493, -0.39808526, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.03029411, -0.8232284 , -0.6669729 , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.34142153, -0.2971679 , -0.28243466, ...,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.38075991,  1.09138716,  0.35219801, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.71001556,  0.14937184, -0.155219  , ...,  1.5       ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.98883726, -0.83681705, -0.33814271, ...,  2.2244898 ,\n",
       "         0.        ,  1.5       ],\n",
       "       [ 0.43650546,  0.76002831,  0.37862008, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.03553234, -0.07334836,  0.13253803, ...,  1.5       ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.00824066, -0.21353225, -0.94826995, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.08007924, -0.51708004, -0.51000954, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.74127519,  1.05529752,  0.45674136, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>85.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>99.1</td>\n",
       "      <td>95.4</td>\n",
       "      <td>65.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>78.8</td>\n",
       "      <td>97.4</td>\n",
       "      <td>71.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>75.1</td>\n",
       "      <td>97.3</td>\n",
       "      <td>80.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>112.8</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18990</th>\n",
       "      <td>31653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>95.3</td>\n",
       "      <td>101.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18991</th>\n",
       "      <td>31654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>119.2</td>\n",
       "      <td>97.6</td>\n",
       "      <td>91.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18992</th>\n",
       "      <td>31656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>99.2</td>\n",
       "      <td>92.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18993</th>\n",
       "      <td>31657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>72.5</td>\n",
       "      <td>98.7</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18994</th>\n",
       "      <td>31658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>104.4</td>\n",
       "      <td>96.2</td>\n",
       "      <td>67.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18995 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          1               1.0               0.0        0.0   \n",
       "1          2               0.0               0.0        0.0   \n",
       "2          4               0.0               0.0        0.0   \n",
       "3          6               1.0               0.0        0.0   \n",
       "4          8               0.0               0.0        0.0   \n",
       "...      ...               ...               ...        ...   \n",
       "18990  31653               0.0               0.0        0.0   \n",
       "18991  31654               0.0               0.0        0.0   \n",
       "18992  31656               1.0               0.0        0.0   \n",
       "18993  31657               0.0               0.0        0.0   \n",
       "18994  31658               0.0               0.0        0.0   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                     0.0                    0.0            1.0   \n",
       "1                     0.0                    0.0            0.0   \n",
       "2                     0.0                    0.0            0.0   \n",
       "3                     0.0                    0.0            0.0   \n",
       "4                     0.0                    0.0            0.0   \n",
       "...                   ...                    ...            ...   \n",
       "18990                 0.0                    0.0            0.0   \n",
       "18991                 0.0                    0.0            0.0   \n",
       "18992                 0.0                    0.0            1.0   \n",
       "18993                 0.0                    0.0            0.0   \n",
       "18994                 0.0                    0.0            0.0   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0                  0.0         0.0                     0.0          0.0   \n",
       "1                  1.0         0.0                     0.0          0.0   \n",
       "2                  0.0         1.0                     0.0          0.0   \n",
       "3                  0.0         1.0                     0.0          0.0   \n",
       "4                  0.0         0.0                     0.0          0.0   \n",
       "...                ...         ...                     ...          ...   \n",
       "18990              0.0         0.0                     0.0          0.0   \n",
       "18991              0.0         0.0                     0.0          0.0   \n",
       "18992              0.0         1.0                     0.0          0.0   \n",
       "18993              0.0         0.0                     0.0          0.0   \n",
       "18994              0.0         0.0                     0.0          0.0   \n",
       "\n",
       "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
       "0               0.0         12.1        85.4       100.0             59.9  \n",
       "1               0.0         20.4        99.1        95.4             65.8  \n",
       "2               0.0         17.8        78.8        97.4             71.8  \n",
       "3               0.0         17.9        75.1        97.3             80.7  \n",
       "4               0.0         18.7       112.8        97.0             92.6  \n",
       "...             ...          ...         ...         ...              ...  \n",
       "18990           0.0         18.5        97.0        95.3            101.4  \n",
       "18991           0.0         19.2       119.2        97.6             91.8  \n",
       "18992           0.0         21.0        93.8        99.2             92.2  \n",
       "18993           0.0         17.8        72.5        98.7             64.0  \n",
       "18994           0.0         16.8       104.4        96.2             67.3  \n",
       "\n",
       "[18995 rows x 16 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         pid\n",
      "0          0\n",
      "1          3\n",
      "2          5\n",
      "3          7\n",
      "4          9\n",
      "...      ...\n",
      "12659  31647\n",
      "12660  31649\n",
      "12661  31651\n",
      "12662  31652\n",
      "12663  31655\n",
      "\n",
      "[12664 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-db40e5f40efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m## Print the testing and traing score. Training score is estimated for the probability estimates not the labels.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     print(clf.validation_score_[np.size(clf.validation_score_) - 1], \" \",\n\u001b[0m\u001b[1;32m     13\u001b[0m           metrics.roc_auc_score(Y_train[:, i],\n\u001b[1;32m     14\u001b[0m                                 clf.predict_proba(X_train)[:, 1], average='micro'))\n",
      "\u001b[0;31mIndexError\u001b[0m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "labels_subtask_1 = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST',\n",
    "                    'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', \n",
    "                    'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "                    'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "Y_train = Y_train[labels_subtask_1].to_numpy()\n",
    "for i, label in enumerate(labels_subtask_1):\n",
    "    ## Fit model\n",
    "    clf = HistGradientBoostingClassifier(scoring = 'roc_auc',\n",
    "                                         random_state = 123).fit(X_train, Y_train[:, i])\n",
    "    \n",
    "    ## Print the testing and traing score. Training score is estimated for the probability estimates not the labels.\n",
    "    print(clf.validation_score_[np.size(clf.validation_score_) - 1], \" \",\n",
    "          metrics.roc_auc_score(Y_train[:, i],\n",
    "                                clf.predict_proba(X_train)[:, 1], average='micro'))\n",
    "    \n",
    "    ## Write to results df\n",
    "    output[label] = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1\n",
    "### Histogram-based Gradient Boosting Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.9368288898293131   0.971955844716475\n",
      "0.7739326298701299   0.9370982421954289\n",
      "0.7395438474996354   0.8227781635493072\n",
      "0.7661201321874631   0.863604620989755\n",
      "0.737128308244282   0.8743783775584116\n",
      "0.8243524930747923   0.8820985417681808\n",
      "0.8664142813173283   0.9300488203798855\n",
      "0.8386329323829322   0.9063001574084065\n",
      "0.7579146241830066   0.9210975183372138\n",
      "0.9442974647887324   0.9891843985498588\n"
     ]
    }
   ],
   "source": [
    "## Define the names of the labels to predict\n",
    "def prob_classsifier(X_train, Y_train, X_test, output):\n",
    "    \"\"\"Classifier that uses the HGBC to give the probability predictions\n",
    "    for the labels of subtask1.\n",
    "    Input:\n",
    "        - X_train: numpy array with the training features\n",
    "        - Y_train: pandas dataframe with the training labels\n",
    "        - X_test: numpy array with the test features\n",
    "        - Output: pandas dataframe with the pid we want to assess\n",
    "    Output:\n",
    "        - Output: pandas dataframe with the predicted values for the labels\n",
    "        \"\"\"\n",
    "    labels_subtask_1 = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST',\n",
    "                    'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', \n",
    "                    'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "                    'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "\n",
    "    ## Write to an array the labels of interest\n",
    "    Y_train = Y_train[labels_subtask_1].to_numpy()\n",
    "\n",
    "    ## For every label in Y_train fit a HGBC and use it to predict the probabilities of X_test\n",
    "    print(\"ROC AUC validation and training score (training score on probability estimates), for each label:\")\n",
    "    for i, label in enumerate(labels_subtask_1):\n",
    "        ## Fit model\n",
    "        clf = HistGradientBoostingClassifier(scoring = 'roc_auc', \n",
    "                                             random_state = 123).fit(X_train, Y_train[:, i])\n",
    "\n",
    "        ## Print the testing and traing score. Training score is estimated for the probability estimates not the labels.\n",
    "        print(clf.validation_score_[np.size(clf.validation_score_) - 1], \" \", \n",
    "              metrics.roc_auc_score(Y_train[:, i],\n",
    "              clf.predict_proba(X_train)[:, 1], average='micro'))\n",
    "\n",
    "        ## Write to results df\n",
    "        output[label] = clf.predict_proba(X_test)[:, 1]\n",
    "    return output\n",
    "\n",
    "output = prob_classsifier(X_train, Y_train, X_test, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.9368288898293131   0.971955844716475\n",
      "0.7739326298701299   0.9370982421954289\n",
      "0.7395438474996354   0.8227781635493072\n",
      "0.7661201321874631   0.863604620989755\n",
      "0.737128308244282   0.8743783775584116\n",
      "0.8243524930747923   0.8820985417681808\n",
      "0.8664142813173283   0.9300488203798855\n",
      "0.8386329323829322   0.9063001574084065\n",
      "0.7579146241830066   0.9210975183372138\n",
      "0.9442974647887324   0.9891843985498588\n"
     ]
    }
   ],
   "source": [
    "def prob_classsifier(X_train, Y_train, X_test, output):\n",
    "    \"\"\"Classifier that uses the HGBC to give the probability predictions\n",
    "    for the labels of subtask1.\n",
    "    Input:\n",
    "        - X_train: numpy array with the training features\n",
    "        - Y_train: pandas dataframe with the training labels\n",
    "        - X_test: numpy array with the test features\n",
    "        - Output: pandas dataframe with the pid we want to assess\n",
    "    Output:\n",
    "        - Output: pandas dataframe with the predicted values for the labels\n",
    "        \"\"\"\n",
    "    labels_subtask_1 = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST',\n",
    "                    'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', \n",
    "                    'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "                    'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "\n",
    "    ## Write to an array the labels of interest\n",
    "    Y_train = Y_train[labels_subtask_1].to_numpy()\n",
    "\n",
    "    ## For every label in Y_train fit a HGBC and use it to predict the probabilities of X_test\n",
    "    print(\"ROC AUC validation and training score (training score on probability estimates), for each label:\")\n",
    "    for i, label in enumerate(labels_subtask_1):\n",
    "        ## Fit model\n",
    "        clf = HistGradientBoostingClassifier(scoring = 'roc_auc', \n",
    "                                             random_state = 123).fit(X_train, Y_train[:, i])\n",
    "\n",
    "        ## Print the testing and traing score. Training score is estimated for the probability estimates not the labels.\n",
    "        print(clf.validation_score_[np.size(clf.validation_score_) - 1], \" \", \n",
    "              metrics.roc_auc_score(Y_train[:, i],\n",
    "              clf.predict_proba(X_train)[:, 1], average='micro'))\n",
    "\n",
    "        ## Write to results df\n",
    "        output[label] = clf.predict_proba(X_test)[:, 1]\n",
    "    return output\n",
    "\n",
    "\n",
    "output = prob_classsifier(X_train, Y_train, X_test, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 2\n",
    "### Histogram-based Gradient Boosting Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(X_train, Y_train, X_test, output):\n",
    "    \"\"\"Classifier that uses the HGBC to give the probability predictions\n",
    "    for the labels of subtask1.\n",
    "    Input:\n",
    "        - X_train: numpy array with the training features\n",
    "        - Y_train: pandas dataframe with the training labels\n",
    "        - X_test: numpy array with the test features\n",
    "        - Output: pandas dataframe with the pid we want to assess\n",
    "    Output:\n",
    "        - Output: pandas dataframe with the predicted LABEL_Sepsis values\n",
    "        \"\"\"\n",
    "    ## Write to an array the labels of interest\n",
    "    Y_train = Y_train['LABEL_Sepsis'].to_numpy()\n",
    "\n",
    "    ## Fit a HGBC and use it to predict the probabilities of X_test\n",
    "    print(\"ROC AUC validation and training score (training score on probability estimates), for each label:\")\n",
    "\n",
    "    ## Fit model\n",
    "    clf = HistGradientBoostingClassifier(scoring = 'roc_auc',\n",
    "                                         random_state = 123).fit(X_train, Y_train)\n",
    "\n",
    "    ## Print the testing and traing score. Trainig score is estimated for the probability estimates not the labels.\n",
    "    print(clf.validation_score_[np.size(clf.validation_score_) - 1],\n",
    "          \" \",\n",
    "          metrics.roc_auc_score(Y_train,\n",
    "                                clf.predict_proba(X_train)[:, 1],\n",
    "                                average='micro'))\n",
    "\n",
    "    ## Write to results df\n",
    "    output['LABEL_Sepsis'] = clf.predict_proba(X_test)[:, 1]\n",
    "    return output\n",
    "\n",
    "output = classifier(X_train, Y_train, X_test, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 3\n",
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def regressor(train_feat, Y_train, test_feat, output):\n",
    "    \"\"\"Regressor that uses Lasso-regression to estimate the values\n",
    "    Input:\n",
    "        - X_train: numpy array with the training features\n",
    "        - Y_train: pandas dataframe with the training labels\n",
    "        - X_test: numpy array with the test features\n",
    "        - Output: pandas dataframe with the pid we want to assess\n",
    "    Output:\n",
    "        - Output: pandas dataframe with the regressed values\n",
    "    \"\"\"\n",
    "    ## Define the features to predict for this rask\n",
    "    labels_subtask_3 = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "    ## Write to an array the labels of interest\n",
    "    Y_train = Y_train[labels_subtask_3].to_numpy()\n",
    "\n",
    "    ## Fit Lasso regression to the data and predict\n",
    "    print(\"Training scores for each label:\")\n",
    "    for i, label in enumerate(labels_subtask_3):\n",
    "        ## Get suffix of the label to predict\n",
    "        sufix = label.split(\"_\", maxsplit = 2)[1] + \"$\"\n",
    "\n",
    "        ## Filter out columns that dont end with the suffix\n",
    "        X_in_loop_train = train_feat.filter(regex = sufix, axis = 1).to_numpy()\n",
    "        X_in_loop_test = test_feat.filter(regex = sufix, axis = 1).to_numpy()\n",
    "\n",
    "        ## Fit model\n",
    "        reg = LassoCV(random_state = 123, \n",
    "                      verbose = False,\n",
    "                      max_iter = 10000).fit(X_in_loop_train, Y_train[:, i])\n",
    "\n",
    "        ## Print training score (the suck)\n",
    "        print(reg.score(X_in_loop_train, Y_train[:, i]))\n",
    "\n",
    "        ## Write to output\n",
    "        output[label] = reg.predict(X_in_loop_test)\n",
    "    return output\n",
    "\n",
    "output = regressor(train_feat, Y_train, test_feat, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Write results to .zip\n",
    "output.to_csv('../output/submission.zip', index=False, float_format='%.3f', compression='zip')\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the score of our submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "VITALS = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "TESTS = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "\n",
    "\n",
    "def get_score(df_true, df_submission):\n",
    "    \"\"\"Function that determines the score of a predicted submission\"\"\"\n",
    "    df_submission = df_submission.sort_values('pid')\n",
    "    df_true = df_true.sort_values('pid')\n",
    "    task1 = np.mean([metrics.roc_auc_score(df_true[entry], df_submission[entry]) for entry in TESTS])\n",
    "    task2 = metrics.roc_auc_score(df_true['LABEL_Sepsis'], df_submission['LABEL_Sepsis'])\n",
    "    task3 = np.mean([0.5 + 0.5 * np.maximum(0, metrics.r2_score(df_true[entry], df_submission[entry])) for entry in VITALS])\n",
    "    score = np.mean([task1, task2, task3])\n",
    "    print(\"Score task 1: \", task1)\n",
    "    print(\"Score task 2: \", task2)\n",
    "    print(\"Score task 3: \", task3)\n",
    "    scores = [task1, task2, task3, score]\n",
    "    return scores\n",
    "\n",
    "\n",
    "def crossvalidation_analysis(X_cross, y_cross, train_feat, folds=5):\n",
    "    \"\"\"Cross-validation analysis of our classifiers and regressors\n",
    "    Input:\n",
    "        - X_cross: numpy array with the training features\n",
    "        - y_cross: pandas dataframe with the training labels\n",
    "        - train_feat: pandas dataframe with the training features\n",
    "    Output:\n",
    "        - scores: pandas dataframe with the scores for each of the cross-validation folds\"\"\"\n",
    "    kf = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X_cross):\n",
    "        X_train, X_test = X_cross[train_index], X_cross[test_index]\n",
    "        Y_train, Y_test = y_cross.loc[train_index].reset_index(), y_cross.loc[test_index].reset_index()\n",
    "        X_train_labels, X_test_labels = train_feat.loc[train_index].reset_index(), train_feat.loc[test_index].reset_index()\n",
    "        output = pd.DataFrame({'pid': Y_test.iloc[:, 0].values})\n",
    "        output = prob_classsifier(X_train, Y_train, X_test, output)\n",
    "        output = classifier(X_train, Y_train, X_test, output)\n",
    "        output = regressor(X_train_labels, Y_train, X_test_labels, output)\n",
    "        print(\"Fold score\", get_score(Y_test, output))\n",
    "        scores.append(get_score(Y_test, output))\n",
    "    \n",
    "    scores = pd.DataFrame(scores,columns=['Task1', \"Task2\", \"Task3\", \"Average\"])\n",
    "    print(\"FINAL SCORE: \", np.mean(scores))\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = crossvalidation_analysis(X_train, Y_train, train_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall scores of our classifiers and regressor\n",
    "\n",
    "In the following table, it is summarised the scores we get for each subtask and the average score for a k-fold (k=5) cross-validation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 1. Binary Relevance and HGBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   | C | kernel | gamma | weight | features | n_features | F1 score | AUC | runtime (min) |\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "| run_1 |  1 |  rbf | scale  |  balanced |  median for NA's and mean  | 35 | 0.598165656150447 | ? | 33 |\n",
    "| run_2 |  1 |  rbf | scale  |  balanced |  median for NA's and mean, max, min, median, sd  | 170 | 0.628216870267411 |?| 102 |\n",
    "| run_3 |  1 |  rbf | scale  |  balanced |  median for NA's and mean, max, min, median, sd, range, skw, kurt  | 272 | 0.649372121402984 | 0.8236937992110356 | 141 |\n",
    "| run_4 |  HGBC |  HGBC | HGBC |  HGBC |  median for NA's and mean, max, min, median, sd, range, skw, kurt  | 272 | 0.871097657278231* | 0.8222653647930391 | 0.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I think the reason for this high score is beacuse the f1_micro is more severe when all labels are taken into account instead of one by one and the averaging. Hence I dont belive the HGBC is superiro in terms of performance, otherwise we would have also observed a big increase in the AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 3. Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainig scores for normalized and unnormalized imputed data restircted to the labels:\n",
    "\n",
    "|nomralized|UN-nomralized|\n",
    "|---|---|\n",
    "|0.37770345083252754 | 0.37759566055685045|\n",
    "|0.5859785441608802  | 0.5856645886174903 |\n",
    "|0.38386074780919743 | 0.3842306307116389 |\n",
    "|0.6144724385873669  | 0.6142282361433877 | \n",
    "\n",
    "The sumbission scores were only a little bit different for normalized and unormalized data. 0.754641671097 and 0.754664968318 respectively. We therofre decide to use normalized data becasue this way we dont need two imputation scripts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
