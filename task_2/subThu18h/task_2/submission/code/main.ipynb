{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "Group name: Cbbayes\n",
    "\n",
    "Team members: mcolomer (mcolomer@student.ethz.ch), pratsink (pratsink@student.ethz.ch) and scastro (scastro@student.ethz.ch)\n",
    "\n",
    "Spring 2021\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We read the already normalized and imputed data. For specifics about the imputation and normalization \n",
    "## see preprocessing.R file\n",
    "test_feat_path = \"../data/test_features_imp.csv\" \n",
    "train_feat_path = \"../data/train_features_imp.csv\" \n",
    "train_lab_path = \"../data/train_labels.csv\"\n",
    "test_feat = pd.read_csv(test_feat_path)\n",
    "train_feat = pd.read_csv(train_feat_path)\n",
    "train_lab = pd.read_csv(train_lab_path)\n",
    "\n",
    "## Order data to make sure that rows in X and Y match\n",
    "test_feat.sort_values(by=['pid'], inplace = True, ignore_index = True)\n",
    "train_feat.sort_values(by=['pid'], inplace = True,ignore_index = True)\n",
    "train_lab.sort_values(by=['pid'], inplace = True, ignore_index = True)\n",
    "\n",
    "## Select exclude the pid column and make into array\n",
    "X_test = test_feat.iloc[:, 1:272].values\n",
    "X_train = train_feat.iloc[:, 1:272].values\n",
    "Y_train = train_lab\n",
    "\n",
    "# Create output file with the pid\n",
    "output = pd.DataFrame({'pid': test_feat.iloc[:, 0].values})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 1\n",
    "### Histogram-based Gradient Boosting Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.9368288898293131   0.971955844716475\n",
      "0.7739326298701299   0.9370982421954289\n",
      "0.7395438474996354   0.8227781635493072\n",
      "0.7661201321874631   0.863604620989755\n",
      "0.737128308244282   0.8743783775584116\n",
      "0.8243524930747923   0.8820985417681808\n",
      "0.8664142813173283   0.9300488203798855\n",
      "0.8386329323829322   0.9063001574084065\n",
      "0.7579146241830066   0.9210975183372138\n",
      "0.9442974647887324   0.9891843985498588\n"
     ]
    }
   ],
   "source": [
    "## Define the names of the labels to predict\n",
    "def prob_classsifier(X_train, Y_train, X_test, output):\n",
    "    \"\"\"Classifier that uses the HGBC to give the probability predictions\n",
    "    for the labels of subtask1.\n",
    "    Input:\n",
    "        - X_train: numpy array with the training features\n",
    "        - Y_train: pandas dataframe with the training labels\n",
    "        - X_test: numpy array with the test features\n",
    "        - Output: pandas dataframe with the pid we want to assess\n",
    "    Output:\n",
    "        - Output: pandas dataframe with the predicted values for the labels\n",
    "        \"\"\"\n",
    "    labels_subtask_1 = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST',\n",
    "                    'LABEL_Alkalinephos', 'LABEL_Bilirubin_total', \n",
    "                    'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "                    'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "\n",
    "    ## Write to an array the labels of interest\n",
    "    Y_train = Y_train[labels_subtask_1].to_numpy()\n",
    "\n",
    "    ## For every label in Y_train fit a HGBC and use it to predict the probabilities of X_test\n",
    "    print(\"ROC AUC validation and training score (training score on probability estimates), for each label:\")\n",
    "    for i, label in enumerate(labels_subtask_1):\n",
    "        ## Fit model\n",
    "        clf = HistGradientBoostingClassifier(scoring = 'roc_auc', \n",
    "                                             random_state = 123).fit(X_train, Y_train[:, i])\n",
    "\n",
    "        ## Print the testing and traing score. Training score is estimated for the probability estimates not the labels.\n",
    "        print(clf.validation_score_[np.size(clf.validation_score_) - 1], \" \", \n",
    "              metrics.roc_auc_score(Y_train[:, i],\n",
    "              clf.predict_proba(X_train)[:, 1], average='micro'))\n",
    "\n",
    "        ## Write to results df\n",
    "        output[label] = clf.predict_proba(X_test)[:, 1]\n",
    "    return output\n",
    "\n",
    "output = prob_classsifier(X_train, Y_train, X_test, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 2\n",
    "### Histogram-based Gradient Boosting Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.7437313990953749   0.8853415748524238\n"
     ]
    }
   ],
   "source": [
    "def classifier(X_train, Y_train, X_test, output):\n",
    "    \"\"\"Classifier that uses the HGBC to give the probability predictions\n",
    "    for the labels of subtask1.\n",
    "    Input:\n",
    "        - X_train: numpy array with the training features\n",
    "        - Y_train: pandas dataframe with the training labels\n",
    "        - X_test: numpy array with the test features\n",
    "        - Output: pandas dataframe with the pid we want to assess\n",
    "    Output:\n",
    "        - Output: pandas dataframe with the predicted LABEL_Sepsis values\n",
    "        \"\"\"\n",
    "    ## Write to an array the labels of interest\n",
    "    Y_train = Y_train['LABEL_Sepsis'].to_numpy()\n",
    "\n",
    "    ## Fit a HGBC and use it to predict the probabilities of X_test\n",
    "    print(\"ROC AUC validation and training score (training score on probability estimates), for each label:\")\n",
    "\n",
    "    ## Fit model\n",
    "    clf = HistGradientBoostingClassifier(scoring = 'roc_auc',\n",
    "                                         random_state = 123).fit(X_train, Y_train)\n",
    "\n",
    "    ## Print the testing and traing score. Trainig score is estimated for the probability estimates not the labels.\n",
    "    print(clf.validation_score_[np.size(clf.validation_score_) - 1],\n",
    "          \" \",\n",
    "          metrics.roc_auc_score(Y_train,\n",
    "                                clf.predict_proba(X_train)[:, 1],\n",
    "                                average='micro'))\n",
    "\n",
    "    ## Write to results df\n",
    "    output['LABEL_Sepsis'] = clf.predict_proba(X_test)[:, 1]\n",
    "    return output\n",
    "\n",
    "output = classifier(X_train, Y_train, X_test, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtask 3\n",
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores for each label:\n",
      "0.37770345083252754\n",
      "0.5859785441608802\n",
      "0.3838607478091973\n",
      "0.614472438587367\n"
     ]
    }
   ],
   "source": [
    "def regressor(train_feat, Y_train, test_feat, output):\n",
    "    \"\"\"Regressor that uses Lasso-regression to estimate the values\n",
    "    Input:\n",
    "        - X_train: numpy array with the training features\n",
    "        - Y_train: pandas dataframe with the training labels\n",
    "        - X_test: numpy array with the test features\n",
    "        - Output: pandas dataframe with the pid we want to assess\n",
    "    Output:\n",
    "        - Output: pandas dataframe with the regressed values\n",
    "    \"\"\"\n",
    "    ## Define the features to predict for this rask\n",
    "    labels_subtask_3 = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "\n",
    "    ## Write to an array the labels of interest\n",
    "    Y_train = Y_train[labels_subtask_3].to_numpy()\n",
    "\n",
    "    ## Fit Lasso regression to the data and predict\n",
    "    print(\"Training scores for each label:\")\n",
    "    for i, label in enumerate(labels_subtask_3):\n",
    "        ## Get suffix of the label to predict\n",
    "        sufix = label.split(\"_\", maxsplit = 2)[1] + \"$\"\n",
    "\n",
    "        ## Filter out columns that dont end with the suffix\n",
    "        X_in_loop_train = train_feat.filter(regex = sufix, axis = 1).to_numpy()\n",
    "        X_in_loop_test = test_feat.filter(regex = sufix, axis = 1).to_numpy()\n",
    "\n",
    "        ## Fit model\n",
    "        reg = LassoCV(random_state = 123, \n",
    "                      verbose = False,\n",
    "                      max_iter = 10000).fit(X_in_loop_train, Y_train[:, i])\n",
    "\n",
    "        ## Print training score (the suck)\n",
    "        print(reg.score(X_in_loop_train, Y_train[:, i]))\n",
    "\n",
    "        ## Write to output\n",
    "        output[label] = reg.predict(X_in_loop_test)\n",
    "    return output\n",
    "\n",
    "output = regressor(train_feat, Y_train, test_feat, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.841947</td>\n",
       "      <td>0.500762</td>\n",
       "      <td>0.767665</td>\n",
       "      <td>0.814490</td>\n",
       "      <td>0.820963</td>\n",
       "      <td>0.564167</td>\n",
       "      <td>0.075179</td>\n",
       "      <td>0.304444</td>\n",
       "      <td>0.032662</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.084461</td>\n",
       "      <td>15.092701</td>\n",
       "      <td>81.921415</td>\n",
       "      <td>98.225746</td>\n",
       "      <td>84.676908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.014213</td>\n",
       "      <td>0.053325</td>\n",
       "      <td>0.189638</td>\n",
       "      <td>0.227850</td>\n",
       "      <td>0.176369</td>\n",
       "      <td>0.045784</td>\n",
       "      <td>0.042676</td>\n",
       "      <td>0.069303</td>\n",
       "      <td>0.015386</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.038164</td>\n",
       "      <td>17.708045</td>\n",
       "      <td>85.290360</td>\n",
       "      <td>96.737910</td>\n",
       "      <td>95.107560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>0.040707</td>\n",
       "      <td>0.160747</td>\n",
       "      <td>0.174051</td>\n",
       "      <td>0.190061</td>\n",
       "      <td>0.069336</td>\n",
       "      <td>0.067896</td>\n",
       "      <td>0.095510</td>\n",
       "      <td>0.018690</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>19.016770</td>\n",
       "      <td>72.983975</td>\n",
       "      <td>95.905009</td>\n",
       "      <td>71.068876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.867916</td>\n",
       "      <td>0.898349</td>\n",
       "      <td>0.847249</td>\n",
       "      <td>0.962370</td>\n",
       "      <td>0.943367</td>\n",
       "      <td>0.419422</td>\n",
       "      <td>0.061377</td>\n",
       "      <td>0.557548</td>\n",
       "      <td>0.345830</td>\n",
       "      <td>0.037326</td>\n",
       "      <td>0.201741</td>\n",
       "      <td>17.501360</td>\n",
       "      <td>86.498119</td>\n",
       "      <td>98.069292</td>\n",
       "      <td>94.273838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.086848</td>\n",
       "      <td>0.070932</td>\n",
       "      <td>0.394263</td>\n",
       "      <td>0.198740</td>\n",
       "      <td>0.333319</td>\n",
       "      <td>0.091845</td>\n",
       "      <td>0.073415</td>\n",
       "      <td>0.087626</td>\n",
       "      <td>0.020094</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>0.036281</td>\n",
       "      <td>20.007447</td>\n",
       "      <td>87.643147</td>\n",
       "      <td>95.843105</td>\n",
       "      <td>91.415635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  LABEL_Alkalinephos  \\\n",
       "0    0          0.841947          0.500762   0.767665            0.814490   \n",
       "1    3          0.014213          0.053325   0.189638            0.227850   \n",
       "2    5          0.030908          0.040707   0.160747            0.174051   \n",
       "3    7          0.867916          0.898349   0.847249            0.962370   \n",
       "4    9          0.086848          0.070932   0.394263            0.198740   \n",
       "\n",
       "   LABEL_Bilirubin_total  LABEL_Lactate  LABEL_TroponinI  LABEL_SaO2  \\\n",
       "0               0.820963       0.564167         0.075179    0.304444   \n",
       "1               0.176369       0.045784         0.042676    0.069303   \n",
       "2               0.190061       0.069336         0.067896    0.095510   \n",
       "3               0.943367       0.419422         0.061377    0.557548   \n",
       "4               0.333319       0.091845         0.073415    0.087626   \n",
       "\n",
       "   LABEL_Bilirubin_direct  LABEL_EtCO2  LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  \\\n",
       "0                0.032662     0.003509      0.084461    15.092701   81.921415   \n",
       "1                0.015386     0.016995      0.038164    17.708045   85.290360   \n",
       "2                0.018690     0.016465      0.025506    19.016770   72.983975   \n",
       "3                0.345830     0.037326      0.201741    17.501360   86.498119   \n",
       "4                0.020094     0.001391      0.036281    20.007447   87.643147   \n",
       "\n",
       "   LABEL_SpO2  LABEL_Heartrate  \n",
       "0   98.225746        84.676908  \n",
       "1   96.737910        95.107560  \n",
       "2   95.905009        71.068876  \n",
       "3   98.069292        94.273838  \n",
       "4   95.843105        91.415635  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write results to .zip\n",
    "output.to_csv('../output/submission.zip', index=False, float_format='%.3f', compression='zip')\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the score of our submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.9394005620420716   0.9590585149615444\n",
      "0.826178216314935   0.9335226318120724\n",
      "0.765157420434237   0.8575271967725269\n",
      "0.743072800078695   0.8766099141066033\n",
      "0.7415546779555077   0.8641397035598006\n",
      "0.8060797409431287   0.9005914863376695\n",
      "0.8931119221411192   0.9598435552959501\n",
      "0.8356163718500501   0.922006993221125\n",
      "0.7049557220708447   0.9476332236180761\n",
      "0.9345515946943531   0.9907608277656279\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.6756182271739217   0.8776616627395168\n",
      "Training scores for each label:\n",
      "0.37916184374386375\n",
      "0.5876642668166384\n",
      "0.38004478408501774\n",
      "0.6135093222785881\n",
      "Score task 1:  0.8175721006246818\n",
      "Score task 2:  0.7184949906561462\n",
      "Score task 3:  0.7463243116873541\n",
      "Fold score [0.8175721006246818, 0.7184949906561462, 0.7463243116873541, 0.7607971343227273]\n",
      "Score task 1:  0.8175721006246818\n",
      "Score task 2:  0.7184949906561462\n",
      "Score task 3:  0.7463243116873541\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.9327553562531142   0.9608958669078664\n",
      "0.7647874986412956   0.8657539797908422\n",
      "0.7432936013757931   0.8601109720486911\n",
      "0.7232454972300797   0.8857447085277594\n",
      "0.7529216505194573   0.8515672819116459\n",
      "0.7980053632227544   0.9064472303619422\n",
      "0.893380046015478   0.9723651275496619\n",
      "0.8203027708592777   0.9201903664057678\n",
      "0.7708725423457334   0.9680630011832607\n",
      "0.9286478873239438   0.9892785225408677\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.6720376777552057   0.8961241888228375\n",
      "Training scores for each label:\n",
      "0.3813889587713527\n",
      "0.5881499366296435\n",
      "0.3913584443268888\n",
      "0.6119566499825806\n",
      "Score task 1:  0.8190494385927242\n",
      "Score task 2:  0.6864256107475577\n",
      "Score task 3:  0.7404995865661262\n",
      "Fold score [0.8190494385927242, 0.6864256107475577, 0.7404995865661262, 0.7486582119688027]\n",
      "Score task 1:  0.8190494385927242\n",
      "Score task 2:  0.6864256107475577\n",
      "Score task 3:  0.7404995865661262\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.9180177916490337   0.9653665764856622\n",
      "0.809064664037587   0.954536880423882\n",
      "0.7544227254216742   0.8947753551932863\n",
      "0.7447269233435071   0.876104736856003\n",
      "0.7544487847222223   0.8866658061733341\n",
      "0.8070274627770082   0.8949767801964325\n",
      "0.893466921028348   0.9389172485493404\n",
      "0.8514985721016548   0.9121031554281704\n",
      "0.7313128798993922   0.9191250769599526\n",
      "0.9241046652643695   0.9862695890849942\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.6988674190469315   0.8848698112338028\n",
      "Training scores for each label:\n",
      "0.37282689703579075\n",
      "0.5834443630854435\n",
      "0.3942954159574319\n",
      "0.6140545825937073\n",
      "Score task 1:  0.8288210178259166\n",
      "Score task 2:  0.7138740296464401\n",
      "Score task 3:  0.742997633156163\n",
      "Fold score [0.8288210178259166, 0.7138740296464401, 0.742997633156163, 0.7618975602095066]\n",
      "Score task 1:  0.8288210178259166\n",
      "Score task 2:  0.7138740296464401\n",
      "Score task 3:  0.742997633156163\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.9247508221825848   0.9537696231717334\n",
      "0.7904068587662337   0.9531138361141558\n",
      "0.7390618513906185   0.8803081437969551\n",
      "0.7307791045563928   0.8700976172489481\n",
      "0.7591816537394285   0.8597881879790208\n",
      "0.8145551315687006   0.9137994537715769\n",
      "0.8970091759002772   0.9556801692887658\n",
      "0.8389191242223483   0.9078905348131064\n",
      "0.701575927478516   0.9139233730632954\n",
      "0.9376951554360977   0.9914341130902499\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.7344920696701371   0.9249758210863512\n",
      "Training scores for each label:\n",
      "0.38017622605413914\n",
      "0.5830265316853415\n",
      "0.40661006829423074\n",
      "0.6134988687546568\n",
      "Score task 1:  0.8250229951467973\n",
      "Score task 2:  0.6923531858158111\n",
      "Score task 3:  0.7351449834981595\n",
      "Fold score [0.8250229951467973, 0.6923531858158111, 0.7351449834981595, 0.7508403881535893]\n",
      "Score task 1:  0.8250229951467973\n",
      "Score task 2:  0.6923531858158111\n",
      "Score task 3:  0.7351449834981595\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.9278757141345747   0.9573356988353984\n",
      "0.785277154052745   0.905828444683459\n",
      "0.7359371986542569   0.8359230299291629\n",
      "0.74736928305286   0.8844970535952209\n",
      "0.7382181999138077   0.8784794390764593\n",
      "0.8032179720704311   0.8801452658745987\n",
      "0.9019002433090024   0.9633662869937695\n",
      "0.8322485906791768   0.9008553512894979\n",
      "0.7490204081632653   0.9710635547087643\n",
      "0.9248389955274597   0.991358181629009\n",
      "ROC AUC validation and training score (training score on probability estimates), for each label:\n",
      "0.6874253033985449   0.9396716604004295\n",
      "Training scores for each label:\n",
      "0.37555585038092876\n",
      "0.5876757236143415\n",
      "0.3580719045509435\n",
      "0.6194282720315745\n",
      "Score task 1:  0.8158874669774085\n",
      "Score task 2:  0.7337707421175469\n",
      "Score task 3:  0.7518192383720933\n",
      "Fold score [0.8158874669774085, 0.7337707421175469, 0.7518192383720933, 0.767159149155683]\n",
      "Score task 1:  0.8158874669774085\n",
      "Score task 2:  0.7337707421175469\n",
      "Score task 3:  0.7518192383720933\n",
      "FINAL SCORE:  Task1      0.821271\n",
      "Task2      0.708984\n",
      "Task3      0.743357\n",
      "Average    0.757870\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "VITALS = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']\n",
    "TESTS = ['LABEL_BaseExcess', 'LABEL_Fibrinogen', 'LABEL_AST', 'LABEL_Alkalinephos', 'LABEL_Bilirubin_total',\n",
    "         'LABEL_Lactate', 'LABEL_TroponinI', 'LABEL_SaO2',\n",
    "         'LABEL_Bilirubin_direct', 'LABEL_EtCO2']\n",
    "\n",
    "\n",
    "def get_score(df_true, df_submission):\n",
    "    \"\"\"Function that determines the score of a predicted submission\"\"\"\n",
    "    df_submission = df_submission.sort_values('pid')\n",
    "    df_true = df_true.sort_values('pid')\n",
    "    task1 = np.mean([metrics.roc_auc_score(df_true[entry], df_submission[entry]) for entry in TESTS])\n",
    "    task2 = metrics.roc_auc_score(df_true['LABEL_Sepsis'], df_submission['LABEL_Sepsis'])\n",
    "    task3 = np.mean([0.5 + 0.5 * np.maximum(0, metrics.r2_score(df_true[entry], df_submission[entry])) for entry in VITALS])\n",
    "    score = np.mean([task1, task2, task3])\n",
    "    print(\"Score task 1: \", task1)\n",
    "    print(\"Score task 2: \", task2)\n",
    "    print(\"Score task 3: \", task3)\n",
    "    scores = [task1, task2, task3, score]\n",
    "    return scores\n",
    "\n",
    "\n",
    "def crossvalidation_analysis(X_cross, y_cross, train_feat, folds=5):\n",
    "    \"\"\"Cross-validation analysis of our classifiers and regressors\n",
    "    Input:\n",
    "        - X_cross: numpy array with the training features\n",
    "        - y_cross: pandas dataframe with the training labels\n",
    "        - train_feat: pandas dataframe with the training features\n",
    "    Output:\n",
    "        - scores: pandas dataframe with the scores for each of the cross-validation folds\"\"\"\n",
    "    kf = KFold(n_splits=folds)\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X_cross):\n",
    "        X_train, X_test = X_cross[train_index], X_cross[test_index]\n",
    "        Y_train, Y_test = y_cross.loc[train_index].reset_index(), y_cross.loc[test_index].reset_index()\n",
    "        X_train_labels, X_test_labels = train_feat.loc[train_index].reset_index(), train_feat.loc[test_index].reset_index()\n",
    "        output = pd.DataFrame({'pid': Y_test.iloc[:, 0].values})\n",
    "        output = prob_classsifier(X_train, Y_train, X_test, output)\n",
    "        output = classifier(X_train, Y_train, X_test, output)\n",
    "        output = regressor(X_train_labels, Y_train, X_test_labels, output)\n",
    "        print(\"Fold score\", get_score(Y_test, output))\n",
    "        scores.append(get_score(Y_test, output))\n",
    "    \n",
    "    scores = pd.DataFrame(scores,columns=['Task1', \"Task2\", \"Task3\", \"Average\"])\n",
    "    print(\"FINAL SCORE: \", np.mean(scores))\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "scores = crossvalidation_analysis(X_train, Y_train, train_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Overall scores of our classifiers and regressor\n",
    "\n",
    "In the following table, it is summarised the scores we get for each subtask and the average score for a k-fold (k=5) cross-validation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task1</th>\n",
       "      <th>Task2</th>\n",
       "      <th>Task3</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817572</td>\n",
       "      <td>0.718495</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.760797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.819049</td>\n",
       "      <td>0.686426</td>\n",
       "      <td>0.740500</td>\n",
       "      <td>0.748658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.828821</td>\n",
       "      <td>0.713874</td>\n",
       "      <td>0.742998</td>\n",
       "      <td>0.761898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.825023</td>\n",
       "      <td>0.692353</td>\n",
       "      <td>0.735145</td>\n",
       "      <td>0.750840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.815887</td>\n",
       "      <td>0.733771</td>\n",
       "      <td>0.751819</td>\n",
       "      <td>0.767159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Task1     Task2     Task3   Average\n",
       "0  0.817572  0.718495  0.746324  0.760797\n",
       "1  0.819049  0.686426  0.740500  0.748658\n",
       "2  0.828821  0.713874  0.742998  0.761898\n",
       "3  0.825023  0.692353  0.735145  0.750840\n",
       "4  0.815887  0.733771  0.751819  0.767159"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Task1</th>\n",
       "      <th>Task2</th>\n",
       "      <th>Task3</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.821271</td>\n",
       "      <td>0.708984</td>\n",
       "      <td>0.743357</td>\n",
       "      <td>0.757870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.019456</td>\n",
       "      <td>0.006248</td>\n",
       "      <td>0.007832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.815887</td>\n",
       "      <td>0.686426</td>\n",
       "      <td>0.735145</td>\n",
       "      <td>0.748658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.817572</td>\n",
       "      <td>0.692353</td>\n",
       "      <td>0.740500</td>\n",
       "      <td>0.750840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.819049</td>\n",
       "      <td>0.713874</td>\n",
       "      <td>0.742998</td>\n",
       "      <td>0.760797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.825023</td>\n",
       "      <td>0.718495</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.761898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.828821</td>\n",
       "      <td>0.733771</td>\n",
       "      <td>0.751819</td>\n",
       "      <td>0.767159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Task1     Task2     Task3   Average\n",
       "count  5.000000  5.000000  5.000000  5.000000\n",
       "mean   0.821271  0.708984  0.743357  0.757870\n",
       "std    0.005447  0.019456  0.006248  0.007832\n",
       "min    0.815887  0.686426  0.735145  0.748658\n",
       "25%    0.817572  0.692353  0.740500  0.750840\n",
       "50%    0.819049  0.713874  0.742998  0.760797\n",
       "75%    0.825023  0.718495  0.746324  0.761898\n",
       "max    0.828821  0.733771  0.751819  0.767159"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 1. Binary Relevance and HGBC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|   | C | kernel | gamma | weight | features | n_features | F1 score | AUC | runtime (min) |\n",
    "|---|---|---|---|---|---|---|---|---|---|\n",
    "| run_1 |  1 |  rbf | scale  |  balanced |  median for NA's and mean  | 35 | 0.598165656150447 | ? | 33 |\n",
    "| run_2 |  1 |  rbf | scale  |  balanced |  median for NA's and mean, max, min, median, sd  | 170 | 0.628216870267411 |?| 102 |\n",
    "| run_3 |  1 |  rbf | scale  |  balanced |  median for NA's and mean, max, min, median, sd, range, skw, kurt  | 272 | 0.649372121402984 | 0.8236937992110356 | 141 |\n",
    "| run_4 |  HGBC |  HGBC | HGBC |  HGBC |  median for NA's and mean, max, min, median, sd, range, skw, kurt  | 272 | 0.871097657278231* | 0.8222653647930391 | 0.5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I think the reason for this high score is beacuse the f1_micro is more severe when all labels are taken into account instead of one by one and the averaging. Hence I dont belive the HGBC is superiro in terms of performance, otherwise we would have also observed a big increase in the AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 3. Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainig scores for normalized and unnormalized imputed data restircted to the labels:\n",
    "\n",
    "|nomralized|UN-nomralized|\n",
    "|---|---|\n",
    "|0.37770345083252754 | 0.37759566055685045|\n",
    "|0.5859785441608802  | 0.5856645886174903 |\n",
    "|0.38386074780919743 | 0.3842306307116389 |\n",
    "|0.6144724385873669  | 0.6142282361433877 | \n",
    "\n",
    "The sumbission scores were only a little bit different for normalized and unormalized data. 0.754641671097 and 0.754664968318 respectively. We therofre decide to use normalized data becasue this way we dont need two imputation scripts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
