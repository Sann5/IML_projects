{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73b7567a",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning - Task 3\n",
    "\n",
    "Group name: Cbbayes\n",
    "\n",
    "Team members: mcolomer (mcolomer@student.ethz.ch), pratsink (pratsink@student.ethz.ch) and scastro (scastro@student.ethz.ch)\n",
    "\n",
    "Spring 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bd818",
   "metadata": {},
   "source": [
    "##Â Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "586b29a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318f830",
   "metadata": {},
   "source": [
    "## Preprocessing: one-hot encoding of the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "546931df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the path to the data file\n",
    "path = \"../data/\"\n",
    "\n",
    "train_data = pd.read_csv(path+\"train.csv\")\n",
    "test_data = pd.read_csv(path+\"test.csv\")\n",
    "\n",
    "aminoacids = [\"R\", \"H\", \"K\",\"D\",\"E\", \"S\",\"T\",\"N\",\"Q\",\"C\",\"U\",\n",
    "             \"G\",\"P\",\"A\",\"I\",\"L\",\"M\",\"F\",\"W\",\"Y\",\"V\"]\n",
    "\n",
    "charge = [1,1,1,-1,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "polarity=[1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0]\n",
    "special=[0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0]\n",
    "\n",
    "\n",
    "#Preprocessing training dataset\n",
    "\n",
    "X_train = train_data[\"Sequence\"].str.split(\"\", n = 4, expand = True)\n",
    "\n",
    "def map_charge(aa, charge, aminoacids):\n",
    "    i = aminoacids.index(aa)\n",
    "    return charge[i]\n",
    "\n",
    "def map_polarity(aa, polarity, aminoacids):\n",
    "    i = aminoacids.index(aa)\n",
    "    return polarity[i]\n",
    "\n",
    "def map_special(aa, special, aminoacids):\n",
    "    i = aminoacids.index(aa)\n",
    "    return special[i]\n",
    "\n",
    "\n",
    "for i in [1,2,3,4]:\n",
    "    train_data[\"pos\"+str(i)] = X_train[i]\n",
    "    train_data = pd.concat([train_data,pd.get_dummies(train_data[\"pos\"+str(i)], prefix=\"pos\"+str(i))],axis=1)\n",
    "    train_data[\"charge\"+str(i)] = train_data[\"pos\"+str(i)].apply(lambda aa: map_charge(aa, charge, aminoacids))\n",
    "    train_data[\"polarity\"+str(i)] = train_data[\"pos\"+str(i)].apply(lambda aa: map_polarity(aa, polarity, aminoacids))\n",
    "    train_data[\"special\"+str(i)] = train_data[\"pos\"+str(i)].apply(lambda aa: map_special(aa, special, aminoacids))\n",
    "    train_data = train_data.drop(columns=[\"pos\"+str(i)])\n",
    "    \n",
    "X_train = train_data.iloc[:, 2:-1].values \n",
    "y_train = train_data.iloc[:,1].values \n",
    "\n",
    "#Preprocessing test dataset\n",
    "\n",
    "X_test = test_data[\"Sequence\"].str.split(\"\", n = 4, expand = True)\n",
    "\n",
    "\n",
    "for i in [1,2,3,4]:\n",
    "    test_data[\"pos\"+str(i)] = X_test[i]\n",
    "    test_data = pd.concat([test_data,pd.get_dummies(test_data[\"pos\"+str(i)], prefix=\"pos\"+str(i))],axis=1)\n",
    "    test_data[\"charge\"+str(i)] = test_data[\"pos\"+str(i)].apply(lambda aa: map_charge(aa, charge, aminoacids))\n",
    "    test_data[\"polarity\"+str(i)] = test_data[\"pos\"+str(i)].apply(lambda aa: map_polarity(aa, polarity, aminoacids))\n",
    "    test_data[\"special\"+str(i)] = test_data[\"pos\"+str(i)].apply(lambda aa: map_special(aa, special, aminoacids))    \n",
    "    test_data = test_data.drop(columns=[\"pos\"+str(i)])\n",
    "    \n",
    "X_test = test_data.iloc[:, 1:-1].values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85dec7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(len(charge))\n",
    "print(len(polarity))\n",
    "print(len(special))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cab5fd",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Class are quite unbalanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "848ee4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112000\n",
      "4213\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "print(sum(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "745c0624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "{'activation': 'relu', 'hidden_layer_sizes': 200}\n",
      "0.873475580285044\n",
      "Ratio positive train: 0.0375625\n",
      "{'mean_fit_time': array([ 90.23113453,  81.59921944, 124.18004191, 120.43785846,\n",
      "       118.76266253, 151.55371642]), 'std_fit_time': array([1.95176852, 5.75963843, 3.49546707, 0.84179842, 1.45810759,\n",
      "       4.20676041]), 'mean_score_time': array([0.25277555, 0.50424051, 0.45561647, 0.32310402, 0.35368836,\n",
      "       0.36651599]), 'std_score_time': array([0.01036942, 0.21191525, 0.02559948, 0.00031197, 0.00053847,\n",
      "       0.00954092]), 'param_activation': masked_array(data=['relu', 'relu', 'relu', 'tanh', 'tanh', 'tanh'],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_hidden_layer_sizes': masked_array(data=[50, 100, 200, 50, 100, 200],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'activation': 'relu', 'hidden_layer_sizes': 50}, {'activation': 'relu', 'hidden_layer_sizes': 100}, {'activation': 'relu', 'hidden_layer_sizes': 200}, {'activation': 'tanh', 'hidden_layer_sizes': 50}, {'activation': 'tanh', 'hidden_layer_sizes': 100}, {'activation': 'tanh', 'hidden_layer_sizes': 200}], 'split0_test_score': array([0.85377821, 0.86783285, 0.86536585, 0.84830918, 0.86973272,\n",
      "       0.86849116]), 'split1_test_score': array([0.86558489, 0.87047898, 0.88158531, 0.86189196, 0.87600097,\n",
      "       0.87245753]), 'mean_test_score': array([0.85968155, 0.86915592, 0.87347558, 0.85510057, 0.87286685,\n",
      "       0.87047434]), 'std_test_score': array([0.00590334, 0.00132307, 0.00810973, 0.00679139, 0.00313412,\n",
      "       0.00198318]), 'rank_test_score': array([5, 4, 1, 6, 2, 3], dtype=int32)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [50, 100, 200],\n",
    "    \"activation\": [\"relu\",\"tanh\"]\n",
    "}\n",
    "# Create a based model\n",
    "cf = MLPClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = cf, param_grid = param_grid, \n",
    "                          cv = 2, n_jobs = -1, verbose = 2, scoring=\"f1\")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "y_test = grid_search.predict(X_test)\n",
    "\n",
    "print(\"Ratio positive train:\", sum(y_test)/len(y_test))\n",
    "\n",
    "print(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5c2fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).to_csv('output_MLP_relu_200hidden.csv', index = False, header = False)             ## Save the results dataframe to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657bc482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
